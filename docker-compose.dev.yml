services:
  embeddings-db:
    image: postgres:15
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT}:5432"
    networks:
      - seaweedfs-network
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 5s
      timeout: 5s
      retries: 5

  redis-jobs:
    image: redis:alpine
    command: redis-server --save "" --appendonly no
    ports:
      - "${REDIS_JOBS_PORT}:6379"
    networks:
      - seaweedfs-network
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]

      interval: 5s
      timeout: 5s
      retries: 5

  redis-commander:
    profiles: [dev]
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis-jobs:6379
    ports:
      - "8081:8081"
    networks:
      - seaweedfs-network
    depends_on:
      - redis-jobs
    restart: unless-stopped

  # File storage stack
  seaweedfs-master:
    image: chrislusf/seaweedfs
    command: "master -ip=seaweedfs-master -port=9333 -port.grpc=19333"
    networks:
      - seaweedfs-network

  seaweedfs-volume:
    image: chrislusf/seaweedfs
    command: 'volume -mserver="seaweedfs-master:9333" -port=8080 -port.grpc=18080 -ip=seaweedfs-volume'
    volumes:
      - seaweedfs_data:/data
    depends_on:
      - seaweedfs-master
    networks:
      - seaweedfs-network

  seaweedfs-filer:
    image: chrislusf/seaweedfs
    ports:
      - "${SEAWEEDFS_FILER_PORT}:8888"
    command: 'filer -master="seaweedfs-master:9333" -port=8888 -port.grpc=18888 -ip=seaweedfs-filer'
    depends_on:
      - seaweedfs-master
      - seaweedfs-volume
    networks:
      - seaweedfs-network
    healthcheck:
      test: [ "CMD", "wget", "--spider", "--quiet", "-Y", "off", "http://seaweedfs-filer:8888/" ]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 20s

  # Triton stack
  triton-model-init:
    profiles: [triton]
    build:
      context: ./storage/model-repository
      dockerfile: Dockerfile.init
    volumes:
      - triton_models:/models
    environment:
      - MODEL_REPOSITORY_PATH=/models
      - MODEL_DOWNLOADS=${MODEL_DOWNLOADS:-}

  triton:
    profiles: [triton]
    build:
      context: ./storage/model-repository
      dockerfile: Dockerfile.triton
    logging:
      driver: "json-file"
      options:
        max-size: "50m"  # Max 50MB per log file
        max-file: "1"
    deploy:
      resources:
        limits:
          memory: 24G  # ESM2-T36 (3B params) requires ~14-22GB for inference
        reservations:
          memory: 16G
    command: >
      tritonserver
      --model-repository=/models
      --model-control-mode=explicit
      --load-model=prot_t5_pipeline
      --load-model=esm2_t33_pipeline
      --load-model=esm2_t36_pipeline
      --load-model=prott5_sec
      --load-model=prott5_cons
      --load-model=bind_embed
      --load-model=seth
      --load-model=tmbed
      --load-model=light_attention_subcell
      --load-model=light_attention_membrane
      --load-model=vespag
      --load-model=exotox
      --disable-auto-complete-config
      --log-verbose=1
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
    volumes:
      - triton_models:/models:ro
    depends_on:
      triton-model-init:
        condition: service_completed_successfully
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/v2/health/ready" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Monitoring stack
  prometheus:
    profiles: [monitoring]
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ${PROMETHEUS_CONFIG_DIR:-./monitoring/prometheus}:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    network_mode: host
    healthcheck:
      test: ["CMD", "wget", "--spider", "--quiet", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Biocentral application stack
  biocentral-server:
    image: ${CI_IMAGE:-}
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "${SERVER_PORT:-9540}:9540"
    volumes:
      - huggingface_models_cache:/app/huggingface_models
      - autoeval_storage:/app/autoeval
      - ./assets:/app/assets
    environment:
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-50000000}
      - POSTGRES_HOST=embeddings-db
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - REDIS_JOBS_HOST=redis-jobs
      - REDIS_JOBS_PORT=6379
      - SEAWEEDFS_FILER_URL=http://seaweedfs-filer:8888
      - HF_HOME=/app/huggingface_models
      - AUTOEVAL_DATA_DIR=/app/autoeval
      - ASSETS_DIR=/app/assets
      - TRITON_GRPC_URL=http://triton:8001
      - TRITON_HTTP_URL=http://triton:8000
      - USE_TRITON=${USE_TRITON:-false}
      - SERVER_DEBUG=${SERVER_DEBUG:-true}
    depends_on:
      redis-jobs:
        condition: service_healthy
      embeddings-db:
        condition: service_healthy
      seaweedfs-filer:
        condition: service_healthy
    networks:
      - seaweedfs-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9540/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  biocentral-worker:
    image: ${CI_IMAGE:-}
    build:
      context: .
      dockerfile: Dockerfile
    command: rq worker-pool --url redis://redis-jobs:6379/0 high default low -n 3
    volumes:
      - huggingface_models_cache:/app/huggingface_models
      - autoeval_storage:/app/autoeval
      - ./assets:/app/assets
    environment:
      - POSTGRES_HOST=embeddings-db
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - REDIS_JOBS_HOST=redis-jobs
      - REDIS_JOBS_PORT=6379
      - SEAWEEDFS_FILER_URL=http://seaweedfs-filer:8888
      - HF_HOME=/app/huggingface_models
      - AUTOEVAL_DATA_DIR=/app/autoeval
      - ASSETS_DIR=/app/assets
      - TRITON_GRPC_URL=http://triton:8001
      - TRITON_HTTP_URL=http://triton:8000
      - USE_TRITON=${USE_TRITON:-false}
    depends_on:
      biocentral-server:
        condition: service_started
      redis-jobs:
        condition: service_healthy
      embeddings-db:
        condition: service_healthy
      seaweedfs-filer:
        condition: service_healthy
    networks:
      - seaweedfs-network

volumes:
  postgres_data:
  seaweedfs_data:
  triton_models:
  prometheus_data:
  huggingface_models_cache:
  autoeval_storage:

networks:
  seaweedfs-network:
    driver: bridge
